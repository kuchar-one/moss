{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ MOSS: Multi-Objective Sound Synthesis\n",
    "\n",
    "## Hled√°n√≠ Pareto-optim√°ln√≠ch smƒõs√≠ spektrogram≈Ø\n",
    "\n",
    "Tento notebook slou≈æ√≠ jako referenƒçn√≠ implementace a sobƒõstaƒçn√° demonstrace syst√©mu MOSS. Algoritmy zde p≈ôesnƒõ odpov√≠daj√≠ webov√©mu frontendu na https://moss.app.kuchar.dpdns.org.\n",
    "\n",
    "### üéØ Definice √∫lohy\n",
    "\n",
    "Nach√°z√≠me se v dom√©nƒõ v√≠cekriteri√°ln√≠ optimalizace (Multi-Objective Optimization). Na≈°√≠m c√≠lem je nal√©zt zobrazen√≠, kter√© k√≥duje s√©mantickou informaci z vizu√°ln√≠ dom√©ny do dom√©ny akustick√©, p≈ôiƒçem≈æ minimalizuje ztr√°tu informace v obou modalit√°ch.\n",
    "\n",
    "Nech≈• $I$ je c√≠lov√Ω obr√°zek (nap≈ô. Mona Lisa) a $A$ je c√≠lov√Ω zvuk (nap≈ô. ƒåajkovsk√Ω). Hled√°me matici spektrogramu $S$, kter√° minimalizuje vektorovou chybovou funkci:\n",
    "$$\\min_{S} F(S) = [L_\\mathrm{visual}(S, I), L_\\mathrm{audio}(S, A)]^T$$\n",
    "\n",
    "Tento probl√©m nem√° jedin√© glob√°ln√≠ ≈ôe≈°en√≠, n√Ωbr≈æ mno≈æinu optim√°ln√≠ch kompromis≈Ø, kterou naz√Ωv√°me Paretovou frontou. ≈òe≈°en√≠ $S^*$ je Pareto-optim√°ln√≠, pokud neexistuje jin√© ≈ôe≈°en√≠ $S'$, pro kter√© by platilo:\n",
    "$$\\forall i: L_i(S') \\leq L_i(S^*) \\wedge \\exists j: L_j(S') < L_j(S^*)$$\n",
    "\n",
    "To jest, nem≈Ø≈æeme vylep≈°it vizu√°ln√≠ podobnost, ani≈æ bychom po≈°kodili zvukovou vƒõrnost, a naopak.\n",
    "\n",
    "### üß† Kl√≠ƒçov√© koncepty a architektura\n",
    "\n",
    "**Spektr√°ln√≠ maskov√°n√≠:**\n",
    "Nam√≠sto p≈ô√≠m√© synt√©zy pixel≈Ø optimalizujeme skal√°rn√≠ pole (masku) $M \\in [0,1]^{F \\times T}$, kter√© ≈ô√≠d√≠ line√°rn√≠ interpolaci mezi magnitudami zdrojov√Ωch sign√°l≈Ø.\n",
    "\n",
    "**Probl√©m spektr√°ln√≠ rekonstrukce:**\n",
    "Lidsk√Ω sluch je extr√©mnƒõ citliv√Ω na ƒçasovou strukturu sign√°lu, kter√° je v STFT reprezentaci zak√≥dov√°na ve f√°zi. Vizu√°ln√≠ rekonstrukce v≈°ak operuje pouze nad amplitudou (magnitudou). Pro zachov√°n√≠ srozumitelnosti audia fixujeme f√°zi c√≠lov√©ho zvuku ($\\phi_\\mathrm{audio}$) a optimalizujeme pouze magnitudu. V√Ωsledn√Ω sign√°l je rekonstruov√°n jako $x(t) = \\text{ISTFT}(|S_\\mathrm{mixed}| \\cdot e^{j\\phi_\\mathrm{audio}})$.\n",
    "\n",
    "**Hybridn√≠ optimalizace:**\n",
    "Pro efektivn√≠ mapov√°n√≠ stavov√©ho prostoru vyu≈æ√≠v√°me dvouf√°zov√Ω p≈ô√≠stup:\n",
    "1. **Gradientn√≠ single-objective optimalizace (ADAM)** pro rychlou konvergenci v urƒçit√Ωch smƒõrech.\n",
    "2. **Evoluƒçn√≠ algoritmus (NSGA-II)** pro glob√°ln√≠ prohled√°v√°n√≠ a zmapov√°n√≠ Paretovy fronty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Z√°kladn√≠ konfigurace a Sign√°lov√© zpracov√°n√≠\n",
    "\n",
    "Zde definujeme parametry pro Short-Time Fourier Transform (STFT). Volba tƒõchto konstant je kritick√° pro vyv√°≈æen√≠ Gaborova limitu, kter√Ω ≈ô√≠k√°, ≈æe nelze m√≠t libovolnƒõ vysokou p≈ôesnost v ƒçase i ve frekvenci souƒçasnƒõ:\n",
    "\n",
    "$$\\sigma_t \\cdot \\sigma_\\omega \\geq \\frac{1}{2}$$\n",
    "\n",
    "* **SAMPLE_RATE = 16000**: Nyquistova frekvence je 8 kHz, co≈æ pokr√Ωv√° vƒõt≈°inu s√©manticky podstatn√©ho spektra pro lidskou ≈ôeƒç a hudbu.\n",
    "* **N_FFT = 1024**: Velikost okna. Urƒçuje frekvenƒçn√≠ rozli≈°en√≠ na $\\approx 15.6$ Hz na bin.\n",
    "* **HOP_LENGTH = 256**: Posun okna (75% p≈ôekryv). Zaji≈°≈•uje hladkou ƒçasovou rekonstrukci a minimalizuje 'spectral leakage' artefakty.\n",
    "\n",
    "Pro urychlen√≠ v√Ωpoƒçt≈Ø zav√°d√≠me koncept **Proxy Optimalizace**. Optimalizaƒçn√≠ smyƒçka bƒõ≈æ√≠ v redukovan√©m rozli≈°en√≠ (`PROXY_HEIGHT = 129`), co≈æ odpov√≠d√° ƒçtvrtinov√©mu vzorkov√°n√≠ frekvenƒçn√≠ osy. V√Ωsledek je n√°slednƒõ upsamplov√°n biline√°rn√≠ interpolac√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import HTML, Audio, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 256\n",
    "WIN_LENGTH = N_FFT\n",
    "GRID_HEIGHT = 64\n",
    "GRID_WIDTH = 128\n",
    "N_PARAMS = GRID_HEIGHT * GRID_WIDTH\n",
    "\n",
    "# Pro zrychlen√≠ prov√°d√≠me proxy optimalizaci v ni≈æ≈°√≠m rozli≈°en√≠\n",
    "PROXY_HEIGHT = 129\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "# Parametry optimalizac√≠, stopping kriterium je v≈°ude poƒçet iterac√≠\n",
    "SINGLE_STEPS = 500\n",
    "PARETO_SEED_STEPS = 200\n",
    "PARETO_GENERATIONS = 50\n",
    "PARETO_SEED_POP = 10\n",
    "PARETO_EVOL_POP = 100\n",
    "\n",
    "def plot_spectrogram(ax, mag_tensor, title=None, show_colorbar=False):\n",
    "    \n",
    "    spec_db = 20 * torch.log10(mag_tensor + 1e-8).cpu().numpy()\n",
    "    ref_max = np.percentile(spec_db, 99.5)\n",
    "    vmin = ref_max - 80\n",
    "    vmax = ref_max\n",
    "    \n",
    "    im = ax.imshow(spec_db, origin='lower', aspect='auto', cmap='magma',\n",
    "                   vmin=vmin, vmax=vmax)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if show_colorbar:\n",
    "        plt.colorbar(im, ax=ax, label='dB')\n",
    "    return im\n",
    "\n",
    "print(f\"PyTorch verze: {torch.__version__}\")\n",
    "print(f\"Za≈ô√≠zen√≠ (hard-coded na CPU pro kompatibilitu): {DEVICE}\")\n",
    "print(f\"Prostor parametr≈Ø: {GRID_HEIGHT}√ó{GRID_WIDTH} = {N_PARAMS} parametr≈Ø\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definice Ztr√°tov√Ωch funkc√≠\n",
    "\n",
    "Aby optimaliz√°tor \"vidƒõl\" a \"sly≈°el\", mus√≠me rozumnƒõ definovat metriky vzd√°lenosti v obou dom√©n√°ch.\n",
    "\n",
    "### üëÅÔ∏è Visual Loss: Mean Absolute Error (MAE)\n",
    "\n",
    "Pro vizu√°ln√≠ slo≈æku pou≈æ√≠v√°me $L_1$ normu. Na rozd√≠l od MSE ($L_2$) je $L_1$ m√©nƒõ citliv√° na odlehl√© hodnoty (outliers) a produkuje ost≈ôej≈°√≠ hrany ve spektrogramu, co≈æ je ≈æ√°douc√≠ pro rozeznatelnost obrazu.\n",
    "\n",
    "$$\\mathcal{L}_\\mathrm{visual} = ||M_\\mathrm{mixed} - M_\\mathrm{image}||_1 = \\frac{1}{N} \\sum_{f,t} |M_\\mathrm{mixed}(f,t) - M_\\mathrm{image}(f,t)|$$\n",
    "\n",
    "### üëÇ Audio Loss: Log-Spectral Distance\n",
    "\n",
    "Pro audio slo≈æku nem≈Ø≈æeme pou≈æ√≠t line√°rn√≠ vzd√°lenost, proto≈æe lidsk√© vn√≠m√°n√≠ hlasitosti je p≈ôibli≈ænƒõ logaritmick√© (v souladu s Weberov√Ωm-Fechnerov√Ωm z√°konem). Minimalizujeme tedy vzd√°lenost v logaritmick√© dom√©nƒõ:\n",
    "\n",
    "$$\\mathcal{L}_\\mathrm{audio} = ||\\log(M_\\mathrm{mixed} + \\epsilon) - \\log(M_\\mathrm{audio} + \\epsilon)||_1$$\n",
    "\n",
    "kde $\\epsilon = 10^{-8}$ zaji≈°≈•uje numerickou stabilitu.\n",
    "\n",
    "### ‚öñÔ∏è Normalizace dle Nadiru\n",
    "\n",
    "Abychom mohli tyto dvƒõ krit√©ria porovn√°vat, normalizujeme je do intervalu [0,1] pomoc√≠ odhadu Nadiru, body loss funkce ≈°k√°lujeme pomoc√≠:\n",
    "\n",
    "*   $\\mathrm{Scale}_\\mathrm{vis} = (\\mathcal{L}_\\mathrm{vis}(A, I))^{-1}$ (Obr√°zkov√° loss funkce ƒçist√©ho zvuku)\n",
    "*   $\\mathrm{Scale}_\\mathrm{aud} = (\\mathcal{L}_\\mathrm{aud}(I, A))^{-1}$ (Zvukov√° loss funkce ƒçist√©ho obr√°zku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_audio_mag_loss(mixed_mag, target_audio_mag):\n",
    "\n",
    "    mixed_log = torch.log(mixed_mag + 1e-8)\n",
    "    target_log = torch.log(target_audio_mag + 1e-8)\n",
    "    target_log = target_log.expand_as(mixed_log)\n",
    "    \n",
    "    loss = F.l1_loss(mixed_log, target_log, reduction='none')\n",
    "    \n",
    "    if mixed_mag.dim() == 3:\n",
    "        return loss.mean(dim=(1, 2))\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def calc_visual_loss(mixed_mag, target_image_mag):\n",
    "\n",
    "    diff = torch.abs(mixed_mag - target_image_mag)\n",
    "    \n",
    "    if mixed_mag.dim() == 3:\n",
    "        return diff.mean(dim=(1, 2))\n",
    "    return diff.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topologie masky a Gaussovsk√© vyhlazen√≠\n",
    "\n",
    "Optimalizujeme matici parametr≈Ø $\\theta \\in \\mathbb{R}^{H \\times W}$. Abychom zabr√°nili vzniku ostr√Ωch spektr√°ln√≠ch diskontinuit, kter√© by se projevily jako zvukov√© a obrazov√© artefakty, aplikujeme na masku konvoluci s Gaussovsk√Ωm j√°drem.\n",
    "\n",
    "Proces transformace parametr≈Ø na masku je\n",
    "$$\\text{mask} = \\sigma(\\text{Upsample}(\\theta * G_\\sigma)),$$\n",
    "\n",
    "kde $G_\\sigma$ je 2D Gaussovsk√© j√°dro\n",
    "$$G_\\sigma(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}}.$$\n",
    "\n",
    "Tato operace funguje jako regularizace, kter√° vynucuje prostorovou korelaci parametr≈Ø, jednodu≈°e ≈ôeƒçeno 'vyhlazuje'; vy≈°≈°√≠ $\\sigma$ vede k \"hlad≈°√≠mu\" zvuku a abstraktnƒõj≈°√≠mu obrazu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur_2d(x, sigma=1.0):\n",
    "\n",
    "    if sigma < 0.5:\n",
    "        return x\n",
    "    \n",
    "    kernel_size = int(6 * sigma) | 1\n",
    "    kernel_size = max(3, kernel_size)\n",
    "    \n",
    "    coords = torch.arange(kernel_size, dtype=x.dtype, device=x.device) - kernel_size // 2\n",
    "    g = torch.exp(-coords**2 / (2 * sigma**2))\n",
    "    g = g / g.sum()\n",
    "    \n",
    "    pad = kernel_size // 2\n",
    "    original_dim = x.dim()\n",
    "    \n",
    "    if x.dim() == 2:\n",
    "        x = x.unsqueeze(0).unsqueeze(0)\n",
    "    elif x.dim() == 3:\n",
    "        x = x.unsqueeze(1)\n",
    "    \n",
    "    x = F.conv2d(F.pad(x, (pad, pad, 0, 0), mode='replicate'), \n",
    "                 g.view(1, 1, 1, -1), padding=0)\n",
    "    x = F.conv2d(F.pad(x, (0, 0, pad, pad), mode='replicate'), \n",
    "                 g.view(1, 1, -1, 1), padding=0)\n",
    "    \n",
    "    if original_dim == 2:\n",
    "        return x.squeeze(0).squeeze(0)\n",
    "    elif original_dim == 3:\n",
    "        return x.squeeze(1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Architektura Enkod√©ru (The Mask Encoder)\n",
    "\n",
    "T≈ô√≠da `MaskEncoder` je srdcem cel√©ho syst√©mu. Zaji≈°≈•uje diferenciabiln√≠ pr≈Øchod z prostoru parametr≈Ø masky do prostoru zvuku.\n",
    "\n",
    "### Gain Staging a Dynamick√Ω Rozsah\n",
    "\n",
    "Jedn√≠m z technicky nejn√°roƒçnƒõj≈°√≠ch aspekt≈Ø je sladƒõn√≠ dynamick√©ho rozsahu obrazu a zvuku.\n",
    "- Spektrogramy audia maj√≠ obrovsk√Ω dynamick√Ω rozsah (ƒçasto > 80 dB).\n",
    "- Obr√°zky (v rozsahu 0‚Äì255) jsou line√°rn√≠ a maj√≠ n√≠zk√Ω kontrast.\n",
    "\n",
    "Implementujeme adaptivn√≠ **Gain Staging**, kter√Ω mapuje jas obrazu do decibelov√© ≈°k√°ly zvuku. Algoritmus vypoƒç√≠t√° ‚Äûstrop‚Äú (ceiling) a ‚Äûpodlahu‚Äú (noise floor) c√≠lov√©ho zvuku a line√°rnƒõ transformuje normalizovan√Ω obraz $I_{norm} \\in [0,1]$ do log-magnitudy zvuku:\n",
    "\n",
    "$$\\log(M_{image}) = I_{norm} \\cdot (dB_{max} - dB_{min}) + dB_{min}$$\n",
    "\n",
    "T√≠m zajist√≠me, ≈æe ƒçern√° barva odpov√≠d√° tichu (noise floor) a b√≠l√° maxim√°ln√≠ hlasitosti, ƒç√≠m≈æ maximalizujeme perceptibilitu obrazu ve spektrogramu zvuku.\n",
    "\n",
    "### Rekonstrukce sign√°lu\n",
    "\n",
    "Jak bylo zm√≠nƒõno v √∫vodu, pro p≈ôevod zpƒõt do ƒçasov√© dom√©ny (waveform) pou≈æ√≠v√°me inverzn√≠ STFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskProcessor(nn.Module):\n",
    "    \"\"\"Zpracov√°v√° parametry masky aplikac√≠ Gaussova rozmaz√°n√≠ a interpolace.\"\"\"\n",
    "\n",
    "    def __init__(self, h, w, sigma, device):\n",
    "        super().__init__()\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.device = device\n",
    "        self._init_gaussian_kernel(sigma)\n",
    "\n",
    "    def _init_gaussian_kernel(self, sigma):\n",
    "        \"\"\"Inicializuje Gaussovo j√°dro pro vyhlazen√≠ masky.\"\"\"\n",
    "        kernel_size = int(2 * math.ceil(2 * sigma) + 1)\n",
    "        x_cord = torch.arange(kernel_size)\n",
    "        x_grid = x_cord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "        y_grid = x_grid.t()\n",
    "        xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "\n",
    "        mean = (kernel_size - 1) / 2.0\n",
    "        variance = sigma**2.0\n",
    "        gaussian_kernel = (1.0 / (2.0 * math.pi * variance)) * torch.exp(\n",
    "            -torch.sum((xy_grid - mean) ** 2.0, dim=-1) / (2 * variance)\n",
    "        )\n",
    "        gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "        self.blur_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.kernel_padding = kernel_size // 2\n",
    "\n",
    "    def forward(self, params, target_h, target_w):\n",
    "        \"\"\"Aplikuje rozmaz√°n√≠ na parametry a zmƒõn√≠ jejich velikost na c√≠lov√© rozli≈°en√≠.\"\"\"\n",
    "        B = params.shape[0]\n",
    "        grid = params.view(B, 1, self.h, self.w)\n",
    "\n",
    "        # Aplikace konvoluce pro vyhlazen√≠ hran masky\n",
    "        grid_blurred = F.conv2d(grid, self.blur_kernel, padding=self.kernel_padding)\n",
    "\n",
    "        # Interpolace na c√≠lovou velikost spektrogramu\n",
    "        mask = F.interpolate(\n",
    "            grid_blurred,\n",
    "            size=(target_h, target_w),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "\n",
    "        return mask.squeeze(1)\n",
    "\n",
    "\n",
    "class MaskEncoder(nn.Module):\n",
    "    \"\"\"K√≥duje parametry do audia pomoc√≠ prol√≠n√°n√≠ spektrogram≈Ø zalo≈æen√©ho na masce.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_image: torch.Tensor,\n",
    "        target_audio_path: str,\n",
    "        grid_height: int = 128,\n",
    "        grid_width: int = 256,\n",
    "        smoothing_sigma: float = 1.0,\n",
    "        device: str = DEVICE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.grid_height = grid_height\n",
    "        self.grid_width = grid_width\n",
    "        self.n_params = grid_height * grid_width\n",
    "        self.smoothing_sigma = smoothing_sigma\n",
    "\n",
    "        # Naƒçten√≠ a p≈ô√≠prava referenƒçn√≠ho audia\n",
    "        audio, sr = torchaudio.load(target_audio_path)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            audio = torchaudio.functional.resample(audio, sr, SAMPLE_RATE)\n",
    "\n",
    "        audio = audio.mean(dim=0, keepdim=True)  # P≈ôevod na mono\n",
    "\n",
    "        self.mask_processor = MaskProcessor(\n",
    "            grid_height, grid_width, smoothing_sigma, device\n",
    "        )\n",
    "\n",
    "        self.register_buffer(\"target_audio_waveform\", audio)\n",
    "\n",
    "        # V√Ωpoƒçet STFT (Kr√°tkodob√° Fourierova transformace)\n",
    "        window = torch.hann_window(N_FFT).to(device)\n",
    "        stft = torch.stft(\n",
    "            audio.to(device),\n",
    "            n_fft=N_FFT,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            win_length=WIN_LENGTH,\n",
    "            window=window,\n",
    "            return_complex=True,\n",
    "        )\n",
    "\n",
    "        self.audio_mag = stft.abs() + 1e-8\n",
    "        self.audio_phase = stft.angle()\n",
    "\n",
    "        self.full_height = self.audio_mag.shape[1]\n",
    "        self.full_width = self.audio_mag.shape[2]\n",
    "\n",
    "        self.audio_log = torch.log(self.audio_mag)\n",
    "\n",
    "        # P≈ô√≠prava c√≠lov√©ho obr√°zku pro spektrogram\n",
    "        img = target_image.to(device)\n",
    "        if img.dim() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        target_h_visual = self.full_height\n",
    "        img_flipped = torch.flip(img, dims=[-2]) # P≈ôeklopen√≠ pro spr√°vnou orientaci frekvenc√≠\n",
    "        img_full_freq = F.interpolate(\n",
    "            img_flipped,\n",
    "            size=(target_h_visual, self.full_width),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        img_resized = img_full_freq\n",
    "\n",
    "        # Dynamick√© ≈ô√≠zen√≠ zisku (Gain Staging) pro sladƒõn√≠ √∫rovn√≠ obrazu a audia\n",
    "        audio_log_max = torch.quantile(self.audio_log, 0.98)\n",
    "        audio_max_val = self.audio_log.max()\n",
    "        audio_floor_val = torch.quantile(self.audio_log, 0.01)\n",
    "\n",
    "        target_ceiling = audio_max_val - 0.5\n",
    "        headroom_nat = (audio_log_max - target_ceiling).item()\n",
    "        dynamic_range_nat = (target_ceiling - audio_floor_val).item() + 0.5\n",
    "        dynamic_range_nat = max(4.0, min(dynamic_range_nat, 12.0))\n",
    "\n",
    "        print(\"Dynamick√© ≈ô√≠zen√≠ zisku:\")\n",
    "        print(f\"  > Max. audio: {audio_max_val:.2f}, Pr√°h (q01): {audio_floor_val:.2f}\")\n",
    "        print(f\"  > C√≠lov√Ω strop: {target_ceiling:.2f}\")\n",
    "        print(f\"  > Adaptivn√≠ dynamick√Ω rozsah: {dynamic_range_nat:.2f}\")\n",
    "\n",
    "        audio_log_ceil = audio_log_max - headroom_nat\n",
    "        audio_log_floor = audio_log_ceil - dynamic_range_nat\n",
    "\n",
    "        self.audio_log = torch.clamp(self.audio_log, min=audio_log_floor)\n",
    "\n",
    "        # Normalizace a √∫prava kontrastu obrazu\n",
    "        img_01 = img_resized.squeeze(0)\n",
    "        img_01 = (img_01 - img_01.min()) / (img_01.max() - img_01.min() + 1e-8)\n",
    "        img_01 = img_01.pow(1.8)\n",
    "\n",
    "        # Mapov√°n√≠ obrazu do logaritmick√© dom√©ny magnitudy audia\n",
    "        self.image_log = img_01 * (audio_log_ceil - audio_log_floor) + audio_log_floor\n",
    "        self.image_mag = torch.exp(self.image_log)\n",
    "        self.audio_mag_static = torch.exp(self.audio_log)\n",
    "\n",
    "        # Nastaven√≠ proxy rozli≈°en√≠ pro rychlej≈°√≠ n√°hledy\n",
    "        self.proxy_height = 129\n",
    "        self.proxy_width = self.full_width // 2\n",
    "\n",
    "        self.image_mag_proxy = F.interpolate(\n",
    "            self.image_mag.unsqueeze(0),\n",
    "            size=(self.proxy_height, self.proxy_width),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).squeeze(0)\n",
    "\n",
    "        self.audio_mag_proxy = F.interpolate(\n",
    "            self.audio_mag_static.unsqueeze(0),\n",
    "            size=(self.proxy_height, self.proxy_width),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).squeeze(0)\n",
    "\n",
    "        self.image_mag_ref = self.image_mag_proxy\n",
    "        self.audio_mag = self.audio_mag_proxy\n",
    "\n",
    "        self.image_mag_full = self.image_mag\n",
    "        self.audio_mag_full = self.audio_mag_static\n",
    "\n",
    "        print(f\"Spektrogram: {self.full_height}√ó{self.full_width}\")\n",
    "        print(f\"Proxy: {self.proxy_height}√ó{self.proxy_width}\")\n",
    "\n",
    "    def _compute_spectrogram(self, mask, img_mag, aud_mag):\n",
    "        \"\"\"Line√°rnƒõ interpoluje mezi magnitudou obrazu a audia pomoc√≠ masky.\"\"\"\n",
    "        return mask * img_mag + (1 - mask) * aud_mag\n",
    "\n",
    "    def _reconstruct_audio(self, mixed_mag, phase):\n",
    "        \"\"\"Rekonstruuje audio sign√°l z magnitudy a f√°ze pomoc√≠ inverzn√≠ STFT.\"\"\"\n",
    "        complex_stft = torch.polar(mixed_mag, phase)\n",
    "\n",
    "        audio_recon = torch.istft(\n",
    "            complex_stft,\n",
    "            n_fft=N_FFT,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            win_length=WIN_LENGTH,\n",
    "            window=torch.hann_window(N_FFT, device=mixed_mag.device),\n",
    "        )\n",
    "\n",
    "        # Normalizace hlasitosti\n",
    "        max_val = audio_recon.abs().max(dim=-1, keepdim=True)[0].clamp(min=1e-8)\n",
    "        audio_recon = audio_recon / max_val * 0.9\n",
    "        return audio_recon\n",
    "\n",
    "    def forward(self, params: torch.Tensor, return_wav: bool = True):\n",
    "        \"\"\"Hlavn√≠ dop≈ôedn√Ω pr≈Øchod: generov√°n√≠ masky, sm√≠ch√°n√≠ a voliteln√° rekonstrukce audia.\"\"\"\n",
    "        batch_size = params.shape[0]\n",
    "\n",
    "        target_h = self.proxy_height if not return_wav else self.full_height\n",
    "        target_w = self.proxy_width if not return_wav else self.full_width\n",
    "\n",
    "        mask = self.mask_processor(params, target_h, target_w)\n",
    "\n",
    "        if not return_wav:\n",
    "            img_mag = self.image_mag_ref.expand(batch_size, -1, -1)\n",
    "            aud_mag = self.audio_mag.expand(batch_size, -1, -1)\n",
    "        else:\n",
    "            img_mag = self.image_mag_full.expand(batch_size, -1, -1)\n",
    "            aud_mag = self.audio_mag_full.expand(batch_size, -1, -1)\n",
    "\n",
    "        phase = self.audio_phase.expand(batch_size, -1, -1) if return_wav else None\n",
    "\n",
    "        mixed_mag = self._compute_spectrogram(mask, img_mag, aud_mag)\n",
    "\n",
    "        audio_recon = None\n",
    "        if return_wav:\n",
    "            audio_recon = self._reconstruct_audio(mixed_mag, phase)\n",
    "\n",
    "        return audio_recon, mixed_mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. P≈ô√≠prava dat\n",
    "Naƒç√≠t√°me vstupn√≠ modality.\n",
    "\n",
    "**Audio**: Je p≈ôevedeno na mono a p≈ôevzorkov√°no na 16kHz.\n",
    "\n",
    "**Obraz**: Je p≈ôeveden na stupnƒõ ≈°edi (Luma), o≈ô√≠znut a interpolov√°n tak, aby jeho v√Ω≈°ka odpov√≠dala Nyquistovƒõ frekvenci v binech ($NFFT/2+1=513$).\n",
    "\n",
    "Parametr `sigma=5.0` byl zvolen empiricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'monalisa.jpg'\n",
    "img_pil = Image.open(img_path).convert('L')\n",
    "img_tensor = torch.from_numpy(np.array(img_pil)).float() / 255.0\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "audio_path = 'tchaikovsky.mp3'\n",
    "waveform, sr = torchaudio.load(audio_path)\n",
    "duration_sec = waveform.shape[-1] / sr\n",
    "raw_width = int(duration_sec * 4.0)\n",
    "grid_width = ((raw_width + 15) // 16) * 16\n",
    "if grid_width < 16:\n",
    "    grid_width = 16\n",
    "grid_height = 64\n",
    "\n",
    "sigma = 5.0\n",
    "encoder = MaskEncoder(\n",
    "    img_tensor, \n",
    "    audio_path,\n",
    "    grid_height=grid_height,\n",
    "    grid_width=grid_width,\n",
    "    smoothing_sigma=sigma,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "GRID_HEIGHT = grid_height\n",
    "GRID_WIDTH = grid_width\n",
    "N_PARAMS = GRID_HEIGHT * GRID_WIDTH\n",
    "\n",
    "print(f\"\\nGrid: {GRID_HEIGHT}√ó{GRID_WIDTH} = {N_PARAMS} parameters\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].imshow(img_pil, cmap='gray')\n",
    "axes[0].set_title('C√≠lov√Ω obr√°zek: Mona Lisa', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "plot_spectrogram(axes[1], encoder.image_mag_full[0], 'Spektrogramov√° Mona Lisa')\n",
    "axes[1].set_xlabel('ƒåas (sn√≠mky)')\n",
    "axes[1].set_ylabel('Frekvence (biny)')\n",
    "\n",
    "plot_spectrogram(axes[2], encoder.audio_mag_full[0], 'C√≠lov√Ω zvuk: ƒåajkovsk√Ω')\n",
    "axes[2].set_xlabel('ƒåas (sn√≠mky)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîä Origin√°ln√≠ ƒåajkovsk√Ω:\")\n",
    "display(Audio(encoder.target_audio_waveform[0].numpy(), rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Spr√°vce Paretovy optimalizace (Pareto Manager)\n",
    "\n",
    "Tato t≈ô√≠da implementuje logiku vektorov√© optimalizace. M√≠sto hled√°n√≠ jednoho bodu spravujeme celou populaci ≈ôe≈°en√≠.\n",
    "\n",
    "### Skalarizace c√≠lov√© funkce\n",
    "\n",
    "Gradientn√≠ metody (jako ADAM) vy≈æaduj√≠ skal√°rn√≠ (jednorozmƒõrnou) ztr√°tovou funkci. Pro vytvo≈ôen√≠ populace rozprost≈ôen√© pod√©l Paretovy fronty pou≈æ√≠v√°me metodu v√°≈æen√Ωch souƒçt≈Ø (Weighted Sum Method).\n",
    "\n",
    "Ka≈æd√Ω jedinec $i$ v populaci optimalizuje unik√°tn√≠ kombinaci vah $w_\\mathrm{vis}^{(i)}, w_\\mathrm{aud}^{(i)}$, pro jeho loss funkci plat√≠\n",
    "\n",
    "$$\\mathcal{L}_\\mathrm{total}^{(i)} = \\gamma \\cdot w_\\mathrm{vis}^{(i)} \\cdot \\hat{\\mathcal{L}}_\\mathrm{vis} + w_\\mathrm{aud}^{(i)} \\cdot \\hat{\\mathcal{L}}_\\mathrm{aud},$$\n",
    "\n",
    "kde $\\gamma = 20.0$ je empirick√Ω v√°hov√Ω faktor. Zjistili jsme, ≈æe audio ztr√°ta je p≈ôes logaritmick√© ≈°k√°lov√°n√≠ v jist√©m smyslu \"tvrdohlavƒõj≈°√≠\" ne≈æ vizu√°ln√≠ ztr√°ta. Bez tohoto faktoru by optimalizace t√©mƒõ≈ô v≈ædy konvergovala k ƒçist√©mu zvuku.\n",
    "\n",
    "Pro kompenzaci neline√°rn√≠ho vztahu mezi pomƒõrem vah a percepc√≠ spektrogramu d√°le v r√°mci optimalizace u≈æ√≠v√°me mocninn√© rozdƒõlen√≠ vah, kter√© vede k lep≈°√≠mu pokryt√≠ objective space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParetoManager(nn.Module):\n",
    "    \"\"\"\n",
    "    Spravuje populaci masek pro optimalizaci.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, pop_size=10, learning_rate=0.05):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.pop_size = pop_size\n",
    "        self.grid_h = encoder.grid_height\n",
    "        self.grid_w = encoder.grid_width\n",
    "        \n",
    "        # Inicializace populace v prostoru logit≈Ø (neomezen√©, sigmoid na [0,1])\n",
    "        self.mask_logits = nn.Parameter(\n",
    "            torch.randn(pop_size, self.grid_h * self.grid_w) * 0.5\n",
    "        )\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Mocninn√© rozdƒõlen√≠ vah (kompenzuje 20x vizu√°ln√≠ pos√≠len√≠)\n",
    "        # ====================================================================\n",
    "        alpha = torch.linspace(0, 1, pop_size)\n",
    "        self.weights_img = (1.0 - alpha).pow(4.0)\n",
    "        self.weights_aud = 1.0 - self.weights_img\n",
    "        \n",
    "        # Normalizace na souƒçet 1\n",
    "        total = self.weights_img + self.weights_aud\n",
    "        self.weights_img = self.weights_img / total\n",
    "        self.weights_aud = self.weights_aud / total\n",
    "        \n",
    "        # Vynucen√≠ extr√©m≈Ø: ƒçist√Ω obraz a ƒçist√© audio\n",
    "        if pop_size >= 2:\n",
    "            with torch.no_grad():\n",
    "                self.mask_logits[0].fill_(10.0)   # Index 0: ƒåist√Ω obraz\n",
    "                self.mask_logits[-1].fill_(-10.0)  # Index -1: ƒåist√© audio\n",
    "        \n",
    "        # Inicializace ADAMa\n",
    "        self.optimizer = optim.Adam([self.mask_logits], lr=learning_rate)\n",
    "        \n",
    "        # Normalizaƒçn√≠ faktory (budou vypoƒçteny)\n",
    "        self.scale_vis = 1.0\n",
    "        self.scale_aud = 1.0\n",
    "        \n",
    "    def calculate_normalization(self):\n",
    "        \"\"\"\n",
    "        V√Ωpoƒçet nejhor≈°√≠ch ztr√°t pro normalizaci c√≠l≈Ø do rozsahu [0, 1].\n",
    "        \"\"\"\n",
    "        print(\"Vypoƒç√≠t√°v√°m normalizaƒçn√≠ faktory...\")\n",
    "        with torch.no_grad():\n",
    "            # Nejhor≈°√≠ vizu√°l: ƒçist√© audio (maska = 0)\n",
    "            max_vis_loss = torch.abs(\n",
    "                self.encoder.audio_mag - self.encoder.image_mag_ref\n",
    "            ).mean().item()\n",
    "            \n",
    "            # Nejhor≈°√≠ audio: ƒçist√Ω obraz (maska = 1)\n",
    "            max_aud_loss = calc_audio_mag_loss(\n",
    "                self.encoder.image_mag_ref, \n",
    "                self.encoder.audio_mag\n",
    "            ).item()\n",
    "            \n",
    "            # Zabr√°nƒõn√≠ dƒõlen√≠ nulou\n",
    "            self.scale_vis = 1.0 / max(max_vis_loss, 1e-6)\n",
    "            self.scale_aud = 1.0 / max(max_aud_loss, 1e-6)\n",
    "            \n",
    "            print(f\"  Max vizu√°ln√≠ ztr√°ta: {max_vis_loss:.4f} ‚Üí mƒõ≈ô√≠tko: {self.scale_vis:.4f}\")\n",
    "            print(f\"  Max audio ztr√°ta:    {max_aud_loss:.4f} ‚Üí mƒõ≈ô√≠tko: {self.scale_aud:.4f}\")\n",
    "    \n",
    "    def optimize_step(self):\n",
    "        \"\"\"\n",
    "        Provede jeden krok gradientn√≠ho sestupu pro v≈°echny ƒçleny populace.\n",
    "                \n",
    "        Returns:\n",
    "            avg_vis: Pr≈Ømƒõrn√° normalizovan√° vizu√°ln√≠ ztr√°ta\n",
    "            avg_aud: Pr≈Ømƒõrn√° normalizovan√° audio ztr√°ta\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Z√≠sk√°n√≠ aktu√°ln√≠ch masek\n",
    "        masks = torch.sigmoid(self.mask_logits)\n",
    "        \n",
    "        # Dop≈ôedn√Ω pr≈Øchod - return_wav=False automaticky pou≈æ√≠v√° PROXY!\n",
    "        _, mixed_mag = self.encoder(masks, return_wav=False)\n",
    "        \n",
    "        # V√Ωpoƒçet ztr√°t (odpov√≠d√° backendu - pou≈æ√≠v√° proxy reference)\n",
    "        diff = torch.abs(mixed_mag - self.encoder.image_mag_ref)\n",
    "        raw_loss_vis = diff.mean(dim=(1, 2))\n",
    "        raw_loss_aud = calc_audio_mag_loss(mixed_mag, self.encoder.audio_mag)\n",
    "        \n",
    "        # Normalizace\n",
    "        loss_vis = raw_loss_vis * self.scale_vis\n",
    "        loss_aud = raw_loss_aud * self.scale_aud\n",
    "        \n",
    "        # Skalarizovan√° ztr√°ta s 20x vizu√°ln√≠m pos√≠len√≠m\n",
    "        total_loss = torch.sum(\n",
    "            self.weights_img * loss_vis * 20.0 + self.weights_aud * loss_aud\n",
    "        )\n",
    "        \n",
    "        # Zpƒõtn√Ω pr≈Øchod a krok optimaliz√°toru\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Vynucen√≠ omezen√≠ kotev\n",
    "        if self.pop_size >= 2:\n",
    "            with torch.no_grad():\n",
    "                self.mask_logits[0].fill_(20.0)\n",
    "                self.mask_logits[-1].fill_(-20.0)\n",
    "        \n",
    "        return loss_vis.detach().mean().item(), loss_aud.detach().mean().item()\n",
    "    \n",
    "    def get_current_front(self):\n",
    "        \"\"\"Z√≠sk√°n√≠ aktu√°ln√≠ch ztr√°t populace pro vykreslov√°n√≠.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            masks = torch.sigmoid(self.mask_logits)\n",
    "            _, mixed_mag = self.encoder(masks, return_wav=False)\n",
    "            \n",
    "            diff = torch.abs(mixed_mag - self.encoder.image_mag_ref)\n",
    "            loss_vis = diff.mean(dim=(1, 2)) * self.scale_vis\n",
    "            loss_aud = calc_audio_mag_loss(mixed_mag, self.encoder.audio_mag) * self.scale_aud\n",
    "            \n",
    "            return loss_vis.numpy(), loss_aud.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Jedno-kriteri√°ln√≠ Optimalizace (Gradient Descent)\n",
    "Zde prov√°d√≠me z√°kladn√≠ \"sond√°≈æ\" prostoru ≈ôe≈°en√≠ pro jednotliv√© pareto-optim√°ln√≠ body.\n",
    "\n",
    "Algoritmus ADAM (Adaptive Moment Estimation) zde funguje jako lok√°ln√≠ vyhled√°vaƒç. D√≠ky tomu, ≈æe m√°me analyticky definovan√© gradienty pro v≈°echny operace (vƒçetnƒõ STFT a interpolac√≠), m≈Ø≈æeme efektivnƒõ naj√≠t optimum pro danou v√°hovou kombinaci.\n",
    "\n",
    "Sledujme v√Ωvoj ztr√°tov√Ωch funkc√≠ v ƒçase. V≈°imnƒõme si, ≈æe vizu√°ln√≠ a audio ztr√°ty jsou dle p≈ôedpokladu v antagonistick√©m vztahu a pokles jedn√© koreluje s n√°r≈Østem druh√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_objective_optimize(encoder, w_vis=0.5, w_aud=0.5, steps=SINGLE_STEPS, lr=0.05):\n",
    "    \"\"\"\n",
    "    Jednokriteri√°ln√≠ optimalizace se zadan√Ωmi vahami.\n",
    "    \n",
    "    Toto p≈ôesnƒõ odpov√≠d√° frontendu pro t≈ôi p≈ôedvolby:\n",
    "    - \"Lep≈°√≠ obraz\": w_vis=0.8, w_aud=0.2\n",
    "    - \"Vyv√°≈æen√©\":    w_vis=0.5, w_aud=0.5\n",
    "    - \"Lep≈°√≠ zvuk\":  w_vis=0.2, w_aud=0.8\n",
    "    \n",
    "    Argumenty:\n",
    "        encoder: Instance MaskEncoder\n",
    "        w_vis: Vizu√°ln√≠ v√°ha (0-1)\n",
    "        w_aud: Audio v√°ha (0-1)\n",
    "        steps: Poƒçet optimalizaƒçn√≠ch krok≈Ø (v√Ωchoz√≠: 500)\n",
    "        lr: Rychlost uƒçen√≠ (learning rate)\n",
    "    \n",
    "    N√°vratov√© hodnoty:\n",
    "        mask: Tenxor optimalizovan√© masky\n",
    "        history: Seznam n-tic (vis_loss, aud_loss)\n",
    "    \"\"\"\n",
    "    # Vytvo≈ôen√≠ mana≈æera pro jednoho jedince\n",
    "    manager = ParetoManager(encoder, pop_size=1, learning_rate=lr)\n",
    "    manager.calculate_normalization()\n",
    "    \n",
    "    # P≈ôeps√°n√≠ vah (normalizace na souƒçet 1)\n",
    "    total_weight = w_vis + w_aud\n",
    "    w_vis_norm = w_vis / total_weight\n",
    "    w_aud_norm = w_aud / total_weight\n",
    "    \n",
    "    manager.weights_img = torch.tensor([w_vis_norm])\n",
    "    manager.weights_aud = torch.tensor([w_aud_norm])\n",
    "    \n",
    "    # Inicializace masky na neutr√°ln√≠ hodnotu (logit = 0 ‚Üí sigmoid = 0.5)\n",
    "    with torch.no_grad():\n",
    "        manager.mask_logits.data.zero_()\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    print(f\"Optimalizace s vahami: Vizu√°ln√≠={w_vis_norm:.2f}, Audio={w_aud_norm:.2f}\")\n",
    "    print(f\"Kroky: {steps}, Rychlost uƒçen√≠: {lr}\")\n",
    "    \n",
    "    for step in range(1, steps + 1):\n",
    "        avg_vis, avg_aud = manager.optimize_step()\n",
    "        history.append((avg_vis, avg_aud))\n",
    "        \n",
    "        if step % 100 == 0 or step == 1:\n",
    "            print(f\"  Krok {step:4d}: Vizu√°ln√≠={avg_vis:.4f}, Audio={avg_aud:.4f}\")\n",
    "    \n",
    "    # Z√≠sk√°n√≠ fin√°ln√≠ masky\n",
    "    final_mask = torch.sigmoid(manager.mask_logits).detach()\n",
    "    \n",
    "    return final_mask, history\n",
    "\n",
    "# Spustit t≈ôi p≈ôedvolby frontendu\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üé® PRIORITA OBRAZU (80/20)\")\n",
    "print(\"=\" * 60)\n",
    "start = time.time()\n",
    "mask_visual, hist_visual = single_objective_optimize(encoder, w_vis=0.8, w_aud=0.2)\n",
    "print(f\"Dokonƒçeno za {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"‚öñÔ∏è VYV√Å≈ΩEN√â (50/50)\")\n",
    "print(\"=\" * 60)\n",
    "start = time.time()\n",
    "mask_balanced, hist_balanced = single_objective_optimize(encoder, w_vis=0.5, w_aud=0.5)\n",
    "print(f\"Dokonƒçeno za {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üîä PRIORITA ZVUKU (20/80)\")\n",
    "print(\"=\" * 60)\n",
    "start = time.time()\n",
    "mask_audio, hist_audio = single_objective_optimize(encoder, w_vis=0.2, w_aud=0.8)\n",
    "print(f\"Dokonƒçeno za {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "# Vykreslen√≠ konvergence\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, hist, title, color in [\n",
    "    (axes[0], hist_visual, 'Vizu√°ln√≠ priorita (80/20)', 'purple'),\n",
    "    (axes[1], hist_balanced, 'Vyv√°≈æen√© (50/50)', 'gray'),\n",
    "    (axes[2], hist_audio, 'Audio priorita (20/80)', 'green'),\n",
    "]:\n",
    "    vis_losses = [h[0] for h in hist]\n",
    "    aud_losses = [h[1] for h in hist]\n",
    "    \n",
    "    ax.plot(vis_losses, label='Vizu√°ln√≠ ztr√°ta', color='purple', alpha=0.8)\n",
    "    ax.plot(aud_losses, label='Audio ztr√°ta', color='green', alpha=0.8)\n",
    "    ax.set_xlabel('Krok')\n",
    "    ax.set_ylabel('Normalizovan√° ztr√°ta')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Vizualizace v√Ωsledk≈Ø\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "results = [\n",
    "    (mask_visual, 'Vizu√°ln√≠ priorita (80/20)'),\n",
    "    (mask_balanced, 'Vyv√°≈æen√© (50/50)'),\n",
    "    (mask_audio, 'Audio priorita (20/80)')\n",
    "]\n",
    "\n",
    "for i, (mask, title) in enumerate(results):\n",
    "    # Generov√°n√≠ v√Ωstupu v pln√©m rozli≈°en√≠\n",
    "    _, mixed_mag = encoder(mask, return_wav=True)  # return_wav=True = pln√© rozli≈°en√≠\n",
    "    \n",
    "    # Vizualizace masky\n",
    "    axes[0, i].imshow(\n",
    "        mask.view(GRID_HEIGHT, GRID_WIDTH).numpy(), \n",
    "        cmap='gray', vmin=0, vmax=1\n",
    "    )\n",
    "    axes[0, i].set_title(f'{title}\\nMaska (b√≠l√°=obraz, ƒçern√°=audio)')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Spektrogram (s mƒõ≈ô√≠tkem odpov√≠daj√≠c√≠m frontendu)\n",
    "    plot_spectrogram(axes[1, i], mixed_mag[0], 'V√Ωsledn√Ω spektrogram')\n",
    "    axes[1, i].set_xlabel('ƒåas')\n",
    "    axes[1, i].set_ylabel('Frekvence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Poslechnƒõte si v√Ωsledky\n",
    "\n",
    "print(\"üé® PRIORITA OBRAZU (80/20):\")\n",
    "wav_visual, _ = encoder(mask_visual, return_wav=True)\n",
    "display(Audio(wav_visual[0].numpy(), rate=SAMPLE_RATE))\n",
    "\n",
    "print(\"‚öñÔ∏è  VYV√Å≈ΩEN√â ≈òE≈†EN√ç (50/50):\")\n",
    "wav_balanced, _ = encoder(mask_balanced, return_wav=True)\n",
    "display(Audio(wav_balanced[0].numpy(), rate=SAMPLE_RATE))\n",
    "\n",
    "print(\"üîä PRIORITA ZVUKU (20/80):\")\n",
    "wav_audio, _ = encoder(mask_audio, return_wav=True)\n",
    "display(Audio(wav_audio[0].numpy(), rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Mapov√°n√≠ Kompletn√≠ Paretovy Fronty (NSGA-II)\n",
    "\n",
    "Pro efektivn√≠ zmapov√°n√≠ bod≈Ø na Paretovƒõ frontƒõ nasazujeme hybridn√≠ optimalizaci.\n",
    "\n",
    "### F√°ze 1: Gradientn√≠ Seeding\n",
    "\n",
    "Nejprve spust√≠me kr√°tkou, intenzivn√≠ d√°vku paraleln√≠ch gradientn√≠ch sestup≈Ø s r≈Øzn√Ωmi vahami. T√≠m nalezneme nƒõkolik jedinc≈Ø bl√≠zko Paretovy fronty. Tyto body slou≈æ√≠ jako vysoce kvalitn√≠ genetick√Ω materi√°l (Seeds) pro dal≈°√≠ f√°zi.\n",
    "\n",
    "### F√°ze 2: Evoluƒçn√≠ Expanze (NSGA-II)\n",
    "\n",
    "P≈ôech√°z√≠me na algoritmus NSGA-II (Non-dominated Sorting Genetic Algorithm II) [Deb et al., 2002]. Tento algoritmus nepracuje s gradienty, ale s p≈ô√≠m√Ωm porovn√°v√°n√≠m fitness vektor≈Ø.\n",
    "\n",
    "**Kl√≠ƒçov√© mechaniky:**\n",
    "\n",
    "*   **Non-dominated Sorting:** ≈òad√≠ populaci do \"vrstev\" podle toho, kolika jin√Ωmi ≈ôe≈°en√≠mi je dan√Ω jedinec dominov√°n. Prvn√≠ vrstva je aktu√°ln√≠ odhad Paretovy fronty.\n",
    "*   **Crowding Distance:** Metrika, kter√° preferuje ≈ôe≈°en√≠ v m√©nƒõ prozkouman√Ωch oblastech fronty. To br√°n√≠ p≈ôedƒçasn√© konvergenci do jednoho bodu a zaji≈°≈•uje biodiverzitu populace a tedy tak√© pokryt√≠ cel√© fronty.\n",
    "*   **SBX Crossover & Polynomial Mutation:** Genetick√© oper√°tory simuluj√≠c√≠ k≈ô√≠≈æen√≠ a mutaci re√°ln√Ωch chromozom≈Ø, aplikovan√© na parametry masky.\n",
    "\n",
    "Tento proces postupnƒõ \"vyhlazuje\" a zahu≈°≈•uje mezeru mezi p≈Øvodn√≠mi gradientn√≠mi body, ƒç√≠m≈æ odhaluje strukturu Paretovy fronty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pareto_optimization(encoder, \n",
    "                            seed_steps=PARETO_SEED_STEPS,\n",
    "                            seed_pop=PARETO_SEED_POP,\n",
    "                            n_gen=PARETO_GENERATIONS,\n",
    "                            evol_pop=PARETO_EVOL_POP):\n",
    "    \"\"\"\n",
    "    Kompletn√≠ optimalizace Paretovy hranice p≈ôesnƒõ odpov√≠daj√≠c√≠ frontendu.\n",
    "    \n",
    "    Argumenty:\n",
    "        encoder: Instance MaskEncoder\n",
    "        seed_steps: Kroky gradientn√≠ho nasazov√°n√≠ (v√Ωchoz√≠: 200)\n",
    "        seed_pop: Velikost poƒç√°teƒçn√≠ populace (v√Ωchoz√≠: 10)\n",
    "        n_gen: Poƒçet generac√≠ NSGA-II (v√Ωchoz√≠: 50)\n",
    "        evol_pop: Velikost evoluƒçn√≠ populace (v√Ωchoz√≠: 100)\n",
    "    \n",
    "    N√°vratov√© hodnoty:\n",
    "        final_X: (N, params) Pareto-optim√°ln√≠ parametry masky\n",
    "        final_F: (N, 2) Pareto-optim√°ln√≠ hodnoty c√≠lov√Ωch funkc√≠\n",
    "        full_history: Seznam sn√≠mk≈Ø populace pro animaci\n",
    "    \"\"\"\n",
    "    from pymoo.core.problem import Problem\n",
    "    from pymoo.core.callback import Callback\n",
    "    from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "    from pymoo.optimize import minimize\n",
    "    from pymoo.operators.crossover.sbx import SBX\n",
    "    from pymoo.operators.mutation.pm import PM\n",
    "    \n",
    "    # ========================================================================\n",
    "    # F√°ze 1: Gradientn√≠ seeding\n",
    "    # ========================================================================\n",
    "    print(\"=\" * 60)\n",
    "    print(\"F√ÅZE 1: GRADIENTN√ç SEEDING\")\n",
    "    print(f\"Populace: {seed_pop}, Krok≈Ø: {seed_steps}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    manager = ParetoManager(encoder, pop_size=seed_pop, learning_rate=0.05)\n",
    "    manager.calculate_normalization()\n",
    "    \n",
    "    phase1_history = []\n",
    "    \n",
    "    for step in range(1, seed_steps + 1):\n",
    "        manager.optimize_step()\n",
    "        \n",
    "        # Z√°znam historie ka≈æd√Ωch 5 krok≈Ø (pro animaci)\n",
    "        if step % 5 == 0:\n",
    "            vis, aud = manager.get_current_front()\n",
    "            phase1_history.append(np.column_stack([vis, aud]))\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            vis, aud = manager.get_current_front()\n",
    "            print(f\"  Krok {step:4d}: Rozsah Vis [{vis.min():.3f}, {vis.max():.3f}], \"\n",
    "                  f\"Rozsah Aud [{aud.min():.3f}, {aud.max():.3f}]\")\n",
    "    \n",
    "    # Extrakce poƒç√°teƒçn√≠ch ≈ôe≈°en√≠ (seeds)\n",
    "    with torch.no_grad():\n",
    "        seed_masks = torch.sigmoid(manager.mask_logits).cpu().numpy()\n",
    "    \n",
    "    print(f\"\\nVygenerov√°no {len(seed_masks)} poƒç√°teƒçn√≠ch ≈ôe≈°en√≠\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # F√°ze 2: Evoluƒçn√≠ expanze (NSGA-II)\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"F√ÅZE 2: EVOLUƒåN√ç ALGORITMUS\")\n",
    "    print(f\"Populace: {evol_pop}, Generac√≠: {n_gen}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    class MOSSProblem(Problem):\n",
    "        def __init__(self, enc, scale_vis, scale_aud):\n",
    "            self.enc = enc\n",
    "            self.scale_vis = scale_vis\n",
    "            self.scale_aud = scale_aud\n",
    "            super().__init__(\n",
    "                n_var=enc.grid_height * enc.grid_width,\n",
    "                n_obj=2,\n",
    "                xl=0.0,\n",
    "                xu=1.0\n",
    "            )\n",
    "        \n",
    "        def _evaluate(self, x, out, *args, **kwargs):\n",
    "            with torch.no_grad():\n",
    "                masks = torch.from_numpy(x).float()\n",
    "                _, mixed_mag = self.enc(masks, return_wav=False)  # proxy automaticky\n",
    "                \n",
    "                vis = calc_visual_loss(mixed_mag, self.enc.image_mag_ref).numpy()\n",
    "                aud = calc_audio_mag_loss(mixed_mag, self.enc.audio_mag).numpy()\n",
    "                \n",
    "                vis = vis * self.scale_vis\n",
    "                aud = aud * self.scale_aud\n",
    "                \n",
    "                out['F'] = np.column_stack([vis, aud])\n",
    "    \n",
    "    class HistoryCallback(Callback):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.history = []\n",
    "        \n",
    "        def notify(self, algorithm):\n",
    "            # Z√°znam p≈ôe≈æiv≈°√≠ populace\n",
    "            self.history.append(algorithm.pop.get('F').copy())\n",
    "    \n",
    "    problem = MOSSProblem(encoder, manager.scale_vis, manager.scale_aud)\n",
    "    \n",
    "    # Inicializace pomoc√≠ seeds + n√°hodn√Ωch hodnot\n",
    "    n_random = evol_pop - len(seed_masks)\n",
    "    X_init = np.vstack([\n",
    "        seed_masks,\n",
    "        np.random.rand(n_random, problem.n_var)\n",
    "    ])\n",
    "    \n",
    "    algorithm = NSGA2(\n",
    "        pop_size=evol_pop,\n",
    "        sampling=X_init,\n",
    "        crossover=SBX(eta=15, prob=0.9),\n",
    "        mutation=PM(eta=20),\n",
    "        eliminate_duplicates=True\n",
    "    )\n",
    "    \n",
    "    callback = HistoryCallback()\n",
    "    \n",
    "    result = minimize(\n",
    "        problem,\n",
    "        algorithm,\n",
    "        ('n_gen', n_gen),\n",
    "        callback=callback,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    full_history = phase1_history + callback.history\n",
    "    \n",
    "    print(f\"\\n‚úÖ Nalezeno {len(result.F)} Pareto-optim√°ln√≠ch ≈ôe≈°en√≠\")\n",
    "    \n",
    "    return result.X, result.F, full_history\n",
    "\n",
    "# Spu≈°tƒõn√≠ pln√© Paretovy optimalizace\n",
    "start = time.time()\n",
    "pareto_X, pareto_F, pareto_history = run_pareto_optimization(encoder)\n",
    "print(f\"\\nCelkov√Ω ƒças: {time.time() - start:.1f}s\")\n",
    "\n",
    "# Vizualizace evoluce\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Fin√°ln√≠ Paretova fronta\n",
    "axes[0].scatter(\n",
    "    pareto_F[:, 0], pareto_F[:, 1],\n",
    "    c='#4ade80', s=60, edgecolors='white', linewidths=1,\n",
    "    label='Fin√°ln√≠ Paretova fronta', zorder=10\n",
    ")\n",
    "\n",
    "# Seeds pro referenci\n",
    "if pareto_history:\n",
    "    seeds = pareto_history[len(pareto_history) // 4]\n",
    "    axes[0].scatter(\n",
    "        seeds[:, 0], seeds[:, 1],\n",
    "        c='purple', s=40, alpha=0.3, label='Seeding'\n",
    "    )\n",
    "\n",
    "axes[0].set_xlabel('Vizu√°ln√≠ ztr√°ta (normalizovan√°) ‚Üì')\n",
    "axes[0].set_ylabel('Audio ztr√°ta (normalizovan√°) ‚Üì')\n",
    "axes[0].set_title('Paretova hranice: Vizu√°ln√≠ vs Audio kvalita')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Evoluce v ƒçase\n",
    "n_hist = len(pareto_history)\n",
    "phase1_len = PARETO_SEED_STEPS // 5  # Historie zaznamenan√° ka≈æd√Ωch 5 krok≈Ø\n",
    "\n",
    "for i, frame in enumerate(pareto_history):\n",
    "    if i < phase1_len:\n",
    "        color = 'purple'\n",
    "        alpha = 0.1 + 0.3 * (i / phase1_len)\n",
    "    else:\n",
    "        color = '#4ade80'\n",
    "        alpha = 0.2 + 0.6 * ((i - phase1_len) / (n_hist - phase1_len))\n",
    "    \n",
    "    axes[1].scatter(frame[:, 0], frame[:, 1], c=color, alpha=alpha, s=20)\n",
    "\n",
    "axes[1].set_xlabel('Vizu√°ln√≠ ztr√°ta (normalizovan√°) ‚Üì')\n",
    "axes[1].set_ylabel('Audio ztr√°ta (normalizovan√°) ‚Üì')\n",
    "axes[1].set_title('Evoluce v ƒçase (fialov√°=nasazov√°n√≠, zelen√°=evoluce)')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animovan√Ω v√Ωvoj\n",
    "\n",
    "Tato animace ukazuje proces optimalizace s:\n",
    "- **F√°ze 1 (Fialov√°)**: Gradientn√≠ nasazov√°n√≠ s hladk√Ωmi p≈ôechody bod≈Ø\n",
    "- **F√°ze 2 (Zelen√°)**: NSGA-II evoluce se stopami mizen√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def create_pareto_animation(history, phase1_frames=40):\n",
    "    \"\"\"\n",
    "    Vytvo≈ô√≠ animovanou vizualizaci Pareto optimalizace.\n",
    "    Odpov√≠d√° stylu animace frontend/backend (svƒõtl√Ω re≈æim).\n",
    "    \"\"\"\n",
    "    if not history or len(history) == 0:\n",
    "        print(\"≈Ω√°dn√° historie k animaci\")\n",
    "        return None\n",
    "    \n",
    "    # Nastaven√≠ grafu (svƒõtl√° verze)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.set_title(\"Animace Pareto optimalizace\", fontsize=14, pad=10)\n",
    "    ax.set_xlabel(\"Vizu√°ln√≠ ztr√°ta (normalizovan√°) ‚Üì\")\n",
    "    ax.set_ylabel(\"Audio ztr√°ta (normalizovan√°) ‚Üì\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Nalezen√≠ glob√°ln√≠ch mez√≠\n",
    "    all_points = np.vstack(history)\n",
    "    min_x, max_x = all_points[:, 0].min(), all_points[:, 0].max()\n",
    "    min_y, max_y = all_points[:, 1].min(), all_points[:, 1].max()\n",
    "    \n",
    "    pad_x = (max_x - min_x) * 0.1 if max_x > min_x else 0.1\n",
    "    pad_y = (max_y - min_y) * 0.1 if max_y > min_y else 0.1\n",
    "    \n",
    "    ax.set_xlim(min_x - pad_x, max_x + pad_x)\n",
    "    ax.set_ylim(min_y - pad_y, max_y + pad_y)\n",
    "    \n",
    "    # Bodov√Ω graf pro aktu√°ln√≠ sn√≠mek\n",
    "    scat = ax.scatter([], [], c='#a855f7', alpha=0.8, s=60, \n",
    "                      edgecolors='white', linewidths=0.5)\n",
    "    \n",
    "    # Bodov√© grafy stop pro efekt dozn√≠v√°n√≠\n",
    "    trail_depth = 5\n",
    "    trail_scats = [ax.scatter([], [], c='#4ade80', alpha=0, s=40) \n",
    "                   for _ in range(trail_depth)]\n",
    "    \n",
    "    text = ax.text(0.02, 0.98, '', transform=ax.transAxes, fontsize=10, va='top')\n",
    "    \n",
    "    prev_positions = [None]  # Pou≈æit√≠ seznamu pro umo≈ænƒõn√≠ mutace v uz√°vƒõru\n",
    "    \n",
    "    def match_points(prev, curr):\n",
    "        \"\"\"P≈ôi≈ôazen√≠ bod≈Ø mezi sn√≠mky pro hladk√Ω p≈ôechod.\"\"\"\n",
    "        if prev is None or len(prev) != len(curr):\n",
    "            return curr\n",
    "        dist = cdist(prev, curr)\n",
    "        matched = np.zeros_like(curr)\n",
    "        used = set()\n",
    "        for i in range(len(prev)):\n",
    "            dists = dist[i].copy()\n",
    "            dists[list(used)] = np.inf\n",
    "            j = np.argmin(dists)\n",
    "            matched[i] = curr[j]\n",
    "            used.add(j)\n",
    "        return matched\n",
    "    \n",
    "    def update(frame):\n",
    "        if frame >= len(history):\n",
    "            return (scat, text, *trail_scats)\n",
    "        \n",
    "        data = history[frame]\n",
    "        \n",
    "        # Hladk√Ω p≈ôechod bƒõhem f√°ze nasazov√°n√≠\n",
    "        if frame < phase1_frames:\n",
    "            data = match_points(prev_positions[0], data)\n",
    "        prev_positions[0] = data.copy()\n",
    "        \n",
    "        scat.set_offsets(data)\n",
    "        \n",
    "        # Barven√≠ podle f√°ze\n",
    "        if frame < phase1_frames:\n",
    "            scat.set_facecolors('#a855f7')  # Fialov√° pro nasazov√°n√≠\n",
    "            text.set_text(f'F√°ze 1: Gradientn√≠ seeding (Krok {frame * 5})')\n",
    "            for ts in trail_scats:\n",
    "                ts.set_offsets(np.empty((0, 2)))\n",
    "        else:\n",
    "            scat.set_facecolors('#4ade80')  # Zelen√° pro evoluci\n",
    "            gen = frame - phase1_frames\n",
    "            text.set_text(f'F√°ze 2: Evoluƒçn√≠ (Gen {gen})')\n",
    "            \n",
    "            # Aktualizace stop s efektem dozn√≠v√°n√≠\n",
    "            for i, ts in enumerate(trail_scats):\n",
    "                trail_frame = frame - (i + 1)\n",
    "                if trail_frame >= phase1_frames and trail_frame < len(history):\n",
    "                    ts.set_offsets(history[trail_frame])\n",
    "                    alpha = 0.3 * (1 - (i / trail_depth))\n",
    "                    ts.set_alpha(alpha)\n",
    "                else:\n",
    "                    ts.set_offsets(np.empty((0, 2)))\n",
    "        \n",
    "        return (scat, text, *trail_scats)\n",
    "    \n",
    "    ani = FuncAnimation(fig, update, frames=len(history), interval=100, blit=True)\n",
    "    plt.close(fig)  # Zabr√°nƒõn√≠ statick√©mu zobrazen√≠\n",
    "    \n",
    "    return ani\n",
    "\n",
    "# Vytvo≈ôen√≠ a zobrazen√≠ animace\n",
    "phase1_len = PARETO_SEED_STEPS // 5\n",
    "ani = create_pareto_animation(pareto_history, phase1_frames=phase1_len)\n",
    "if ani:\n",
    "    display(HTML(ani.to_jshtml()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Z√°vƒõreƒçn√° anal√Ωza a Shrnut√≠\n",
    "\n",
    "V tomto notebooku jsme √∫spƒõ≈°nƒõ implementovali end-to-end syst√©m pro synt√©zu spektrogram≈Ø nesouc√≠ch zvuk a obraz z√°rove≈à. Hlavn√≠m v√Ωsledkem je relativnƒõ rychl√© nalezen√≠ Paretovy fronty pro v√≠cekriteri√°ln√≠ optimalizaci s velmi vysokou dimenz√≠ prostoru parametr≈Ø.\n",
    "\n",
    "### Designov√° rozhodnut√≠ v kontextu fyziky\n",
    "\n",
    "*   **ƒåas vs. Frekvence:** Volba $N_{FFT}=1024$ p≈ôi 16kHz je p≈ô√≠m√Ωm d≈Øsledkem snahy vyv√°≈æit ƒçasovou lokalizaci (pro rytmus) a frekvenƒçn√≠ rozli≈°en√≠ (pro detaily obrazu).\n",
    "*   **F√°zov√° invariance:** Rozhodnut√≠ ignorovat vizu√°ln√≠ f√°zi a vnutit f√°zi audia je to, co ƒçin√≠ v√Ωsledek poslouchateln√Ωm. P≈ôedpokl√°d√°me, ≈æe s√©mantika zvuku je nesena ƒçasov√Ωm uspo≈ô√°d√°n√≠m f√°z√≠.\n",
    "\n",
    "### Citace a Odkazy\n",
    "\n",
    "*   **NSGA-II:** Deb, K., Pratap, A., Agarwal, S., & Meyarivan, T. (2002). A fast and elitist multiobjective genetic algorithm: NSGA-II. *IEEE Transactions on Evolutionary Computation*.\n",
    "*   **STFT Reconstruction:** Griffin, D., & Lim, J. (1984). Signal estimation from modified short-time Fourier transform. *IEEE Transactions on ASSP*.\n",
    "*   **Pareto Optimality:** Pareto, V. (1896). *Cours d'√©conomie politique*.\n",
    "*   **ADAM:** Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. *arXiv preprint arXiv:1412.6980*.\n",
    "*   **L1 Loss in Image Synthesis:** Zhao, H., Gallo, O., Frosio, I., & Kautz, J. (2016). Loss functions for image restoration with neural networks. *IEEE Transactions on Computational Imaging*, 3(1), 47-57.\n",
    "*   **Phase Reconstruction:** Allen, J. B. (1977). Short term spectral analysis, synthesis, and modification by discrete Fourier transform. *IEEE Transactions on Acoustics, Speech, and Signal Processing*, 25(3), 235-238.\n",
    "*   **Psychoacoustics:** Fastl, H., & Zwicker, E. (2007). *Psychoacoustics: Facts and models*. Springer.\n",
    "*   **Tacotron and Log L1 loss:** Wang, Y., et al. (2017). \"Tacotron: Towards end-to-end speech synthesis.\" *Interspeech*.\n",
    "\n",
    "Tento syst√©m demonstruje, ≈æe i s relativnƒõ jednoduch√Ωmi stavebn√≠mi kameny (STFT, line√°rn√≠ interpolace) a robustn√≠ optimalizac√≠ lze dos√°hnout netrivi√°ln√≠ch a mo≈æn√° umƒõlecky zaj√≠mav√Ωch v√Ωsledk≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr≈Øzkum Paretovy fronty\n",
    "\n",
    "sorted_idx = np.argsort(pareto_F[:, 0])\n",
    "\n",
    "# V√Ωbƒõr 5 vzork≈Ø pod√©l hranice\n",
    "n_samples = min(5, len(sorted_idx))\n",
    "sample_indices = [sorted_idx[int(i * (len(sorted_idx) // 3) / (n_samples - 1))] \n",
    "                  for i in range(n_samples)]\n",
    "\n",
    "fig, axes = plt.subplots(2, n_samples, figsize=(4 * n_samples, 8))\n",
    "\n",
    "for col, idx in enumerate(sample_indices):\n",
    "    mask = torch.from_numpy(pareto_X[idx:idx+1]).float()\n",
    "    wav, mixed_mag = encoder(mask, return_wav=True)\n",
    "    \n",
    "    # Maska\n",
    "    axes[0, col].imshow(\n",
    "        mask.view(GRID_HEIGHT, GRID_WIDTH).numpy(),\n",
    "        cmap='gray', vmin=0, vmax=1\n",
    "    )\n",
    "    axes[0, col].set_title(f'V:{pareto_F[idx,0]:.3f}, A:{pareto_F[idx,1]:.3f}')\n",
    "    axes[0, col].axis('off')\n",
    "    \n",
    "    # Spektrogram (≈°k√°lov√°n√≠ odpov√≠daj√≠c√≠ frontendu)\n",
    "    plot_spectrogram(axes[1, col], mixed_mag[0])\n",
    "    axes[1, col].axis('off')\n",
    "\n",
    "plt.suptitle('Vzorky nap≈ô√≠ƒç Paretovou frontou (Vlevo=Nejlep≈°√≠ vizu√°ln√≠, Vpravo=Nejlep≈°√≠ audio)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Poslech vzork≈Ø\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    mask = torch.from_numpy(pareto_X[idx:idx+1]).float()\n",
    "    wav, _ = encoder(mask, return_wav=True)\n",
    "    print(f\"\\nüéµ Vzorek {i+1}: Vizu√°ln√≠={pareto_F[idx,0]:.3f}, Audio={pareto_F[idx,1]:.3f}\")\n",
    "    display(Audio(wav[0].numpy(), rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Vytvo≈ôil s üíú [Vojtƒõch Kucha≈ô](https://github.com/kuchar-one)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
